{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 370,
      "metadata": {
        "id": "3UczvCdyLAuZ"
      },
      "outputs": [],
      "source": [
        "# sklearn-useful library for machine learning in Python\n",
        "# numpy-support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
        "# pandas-it offers data structures and operations for manipulating numerical tables and time series\n",
        "\n",
        "\n",
        "\n",
        "# numpy,pandas,sklearn,matplotlib are libraries\n",
        "# pyplot is a sub-library of matplotlib library(plotting library in Python)\n",
        "# model_selection is a package in sklearn library(process of selecting one final machine learning model from among a collection of candidate machine learning)\n",
        "# train_test_split is a module(a file consisting of Python code)\n",
        "# datasets is a module in sklearn library (includes utilities to load datasets, including methods to load and fetch popular reference datasets.)\n",
        "# load_breast_cancer is a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 371,
      "metadata": {
        "id": "tQ_S4Sm41KOC"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {
        "id": "EPcL5Nezon7f"
      },
      "outputs": [],
      "source": [
        "#Creating a instance of load_breast_cancer(class like)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {
        "id": "kiJp381A1blz"
      },
      "outputs": [],
      "source": [
        "cancer=load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {
        "id": "jBXLjlJXozJ0"
      },
      "outputs": [],
      "source": [
        "#Getting the keys used in load_breast_cancer dataset, so as to further evaluate by using these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94urL8d51cBD",
        "outputId": "22775c39-f0ca-4cd0-d205-f24b3ceb84df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "execution_count": 375,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "rwsR6mYwpCLg"
      },
      "outputs": [],
      "source": [
        "#Getting the values of every key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOs9aJiv1cZe",
        "outputId": "4a0ae29d-bf1e-4d30-a562-116ca4a406a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "execution_count": 377,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "byi_41gC1cue",
        "outputId": "b54de064-ea88-43f2-aa3e-07d4c08671e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.'"
            ]
          },
          "execution_count": 378,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.DESCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NFup-vx1dCT",
        "outputId": "f4249d27-08fb-4a93-afce-e0a3f2c50534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "execution_count": 379,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHduc7GN1dZF",
        "outputId": "0586097d-d7b8-444c-f3f4-d514066cb15c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "execution_count": 380,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri9Dhm9gukpw",
        "outputId": "76e8aa83-528b-46e7-b80f-9fc49abf39d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "execution_count": 381,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3BC3KHV6uqI0",
        "outputId": "b3aa2db7-811d-4ab2-c199-aec32212bc07"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/breast_cancer.csv'"
            ]
          },
          "execution_count": 382,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "id": "eaQXGy11pM51"
      },
      "outputs": [],
      "source": [
        "#Converting the given dataset to data frame using pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "id": "XmrZVeZwut6S"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame(cancer.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "ZK2EdBv5vCM2",
        "outputId": "9200da54-eddb-43d0-f079-4eb11857a629"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0      1       2       3   ...      26      27      28       29\n",
              "0    17.99  10.38  122.80  1001.0  ...  0.7119  0.2654  0.4601  0.11890\n",
              "1    20.57  17.77  132.90  1326.0  ...  0.2416  0.1860  0.2750  0.08902\n",
              "2    19.69  21.25  130.00  1203.0  ...  0.4504  0.2430  0.3613  0.08758\n",
              "3    11.42  20.38   77.58   386.1  ...  0.6869  0.2575  0.6638  0.17300\n",
              "4    20.29  14.34  135.10  1297.0  ...  0.4000  0.1625  0.2364  0.07678\n",
              "..     ...    ...     ...     ...  ...     ...     ...     ...      ...\n",
              "564  21.56  22.39  142.00  1479.0  ...  0.4107  0.2216  0.2060  0.07115\n",
              "565  20.13  28.25  131.20  1261.0  ...  0.3215  0.1628  0.2572  0.06637\n",
              "566  16.60  28.08  108.30   858.1  ...  0.3403  0.1418  0.2218  0.07820\n",
              "567  20.60  29.33  140.10  1265.0  ...  0.9387  0.2650  0.4087  0.12400\n",
              "568   7.76  24.54   47.92   181.0  ...  0.0000  0.0000  0.2871  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 385,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 386,
      "metadata": {
        "id": "K0pcrUZZpaw0"
      },
      "outputs": [],
      "source": [
        "#Assigning feature_names to each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "HdFj0ntuvDVu"
      },
      "outputs": [],
      "source": [
        "df.columns=cancer.feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "zEHuhxN7vIip",
        "outputId": "8eb6eec7-0019-4342-8696-1032a5fb4d0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0          17.99         10.38  ...          0.4601                  0.11890\n",
              "1          20.57         17.77  ...          0.2750                  0.08902\n",
              "2          19.69         21.25  ...          0.3613                  0.08758\n",
              "3          11.42         20.38  ...          0.6638                  0.17300\n",
              "4          20.29         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564        21.56         22.39  ...          0.2060                  0.07115\n",
              "565        20.13         28.25  ...          0.2572                  0.06637\n",
              "566        16.60         28.08  ...          0.2218                  0.07820\n",
              "567        20.60         29.33  ...          0.4087                  0.12400\n",
              "568         7.76         24.54  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 388,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 389,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "TcB2nLsavJdr",
        "outputId": "0976c924-5ccc-4c28-84b0-b57ebfea1f66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 389,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 390,
      "metadata": {
        "id": "ZjNBFlPbqBFh"
      },
      "outputs": [],
      "source": [
        "#As of now the feature names are our X coordinate and we too require Y coordinate values that are stored in the target attribute in the keys and we assign it in y.\n",
        "#And too converting it to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ByBLx74uvM5e",
        "outputId": "8f7f5305-f2e6-4661-88f2-49b312836f22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ]
          },
          "execution_count": 391,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y=pd.DataFrame(cancer.target)\n",
        "y.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "id": "XgeCr_-WqYD_"
      },
      "outputs": [],
      "source": [
        "#df.isnull().sum() returns the number of missing values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 393,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNAx2NQMwPZI",
        "outputId": "ff051b4e-f73d-40f0-98fd-591429a0a921"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 393,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()\n",
        "\n",
        "\n",
        "\n",
        "#IF suppose all the values were not zero then we need to replace it without any another no. or so.\n",
        "#Therfore for this purpose Imputer is required\n",
        "\n",
        "\n",
        "#The SimpleImputer class provides basic strategies for imputing missing values. Missing values can be imputed with a provided constant value, or using the statistics (mean, median or most frequent) of each column in which the missing values are located. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 394,
      "metadata": {
        "id": "qpVgA-0aqR1W"
      },
      "outputs": [],
      "source": [
        "#df.isnull().sum().sum() returns the number of missing values in the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 395,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4_IUXIUwm1-",
        "outputId": "86474fee-3a16-4f30-f785-068f91496edc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 395,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 396,
      "metadata": {
        "id": "a-YspAyzqkEE"
      },
      "outputs": [],
      "source": [
        "#df.isna().sum() returns the number of missing values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 397,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEF9mozUw3iV",
        "outputId": "d2438029-a404-4781-8c16-bb8e94ae6c69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 397,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 398,
      "metadata": {
        "id": "eRp0mKeErQLg"
      },
      "outputs": [],
      "source": [
        "#df.isna().sum().sum() returns the number of missing values in the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 399,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOHpuHjww78c",
        "outputId": "908d28ff-45b6-4df0-f1aa-1b7e5dde9fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 399,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 400,
      "metadata": {
        "id": "eLy1gaA4rfJM"
      },
      "outputs": [],
      "source": [
        "#df.isnull().values.any() returns False if there are no Null values or else True, if there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 401,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LnZ2eZMw_sq",
        "outputId": "6220dba4-095d-4ba3-ce37-0ad1da240a03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 401,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 402,
      "metadata": {
        "id": "pPm7YSlBsP0_"
      },
      "outputs": [],
      "source": [
        "#train_test_split is a function in Sklearn model selection for splitting data arrays into two subsets: for training data and for testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 403,
      "metadata": {
        "id": "KCPNbFXFxcg1"
      },
      "outputs": [],
      "source": [
        "X_Train,X_Test,Y_Train,Y_Test=train_test_split(df,y,train_size=0.70,random_state=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 404,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "oLv4pKZDzSVe",
        "outputId": "cb566c6c-623e-40b5-e8b5-a975fd068d3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>18.45</td>\n",
              "      <td>21.91</td>\n",
              "      <td>120.20</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>0.09430</td>\n",
              "      <td>0.09709</td>\n",
              "      <td>0.11530</td>\n",
              "      <td>0.06847</td>\n",
              "      <td>0.1692</td>\n",
              "      <td>0.05727</td>\n",
              "      <td>0.5959</td>\n",
              "      <td>1.2020</td>\n",
              "      <td>3.766</td>\n",
              "      <td>68.35</td>\n",
              "      <td>0.006001</td>\n",
              "      <td>0.01422</td>\n",
              "      <td>0.02855</td>\n",
              "      <td>0.009148</td>\n",
              "      <td>0.01492</td>\n",
              "      <td>0.002205</td>\n",
              "      <td>22.52</td>\n",
              "      <td>31.39</td>\n",
              "      <td>145.60</td>\n",
              "      <td>1590.0</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.2275</td>\n",
              "      <td>0.3965</td>\n",
              "      <td>0.13790</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.07610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>13.85</td>\n",
              "      <td>15.18</td>\n",
              "      <td>88.99</td>\n",
              "      <td>587.4</td>\n",
              "      <td>0.09516</td>\n",
              "      <td>0.07688</td>\n",
              "      <td>0.04479</td>\n",
              "      <td>0.03711</td>\n",
              "      <td>0.2110</td>\n",
              "      <td>0.05853</td>\n",
              "      <td>0.2479</td>\n",
              "      <td>0.9195</td>\n",
              "      <td>1.830</td>\n",
              "      <td>19.41</td>\n",
              "      <td>0.004235</td>\n",
              "      <td>0.01541</td>\n",
              "      <td>0.01457</td>\n",
              "      <td>0.010430</td>\n",
              "      <td>0.01528</td>\n",
              "      <td>0.001593</td>\n",
              "      <td>14.98</td>\n",
              "      <td>21.74</td>\n",
              "      <td>98.37</td>\n",
              "      <td>670.0</td>\n",
              "      <td>0.1185</td>\n",
              "      <td>0.1724</td>\n",
              "      <td>0.1456</td>\n",
              "      <td>0.09993</td>\n",
              "      <td>0.2955</td>\n",
              "      <td>0.06912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>18.81</td>\n",
              "      <td>19.98</td>\n",
              "      <td>120.90</td>\n",
              "      <td>1102.0</td>\n",
              "      <td>0.08923</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.08020</td>\n",
              "      <td>0.05843</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>0.04996</td>\n",
              "      <td>0.3283</td>\n",
              "      <td>0.8280</td>\n",
              "      <td>2.363</td>\n",
              "      <td>36.74</td>\n",
              "      <td>0.007571</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.02623</td>\n",
              "      <td>0.014630</td>\n",
              "      <td>0.01930</td>\n",
              "      <td>0.001676</td>\n",
              "      <td>19.96</td>\n",
              "      <td>24.30</td>\n",
              "      <td>129.00</td>\n",
              "      <td>1236.0</td>\n",
              "      <td>0.1243</td>\n",
              "      <td>0.1160</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.12940</td>\n",
              "      <td>0.2567</td>\n",
              "      <td>0.05737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>17.68</td>\n",
              "      <td>20.74</td>\n",
              "      <td>117.40</td>\n",
              "      <td>963.7</td>\n",
              "      <td>0.11150</td>\n",
              "      <td>0.16650</td>\n",
              "      <td>0.18550</td>\n",
              "      <td>0.10540</td>\n",
              "      <td>0.1971</td>\n",
              "      <td>0.06166</td>\n",
              "      <td>0.8113</td>\n",
              "      <td>1.4000</td>\n",
              "      <td>5.540</td>\n",
              "      <td>93.91</td>\n",
              "      <td>0.009037</td>\n",
              "      <td>0.04954</td>\n",
              "      <td>0.05206</td>\n",
              "      <td>0.018410</td>\n",
              "      <td>0.01778</td>\n",
              "      <td>0.004968</td>\n",
              "      <td>20.47</td>\n",
              "      <td>25.11</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.3498</td>\n",
              "      <td>0.3583</td>\n",
              "      <td>0.15150</td>\n",
              "      <td>0.2463</td>\n",
              "      <td>0.07738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>14.20</td>\n",
              "      <td>20.53</td>\n",
              "      <td>92.41</td>\n",
              "      <td>618.4</td>\n",
              "      <td>0.08931</td>\n",
              "      <td>0.11080</td>\n",
              "      <td>0.05063</td>\n",
              "      <td>0.03058</td>\n",
              "      <td>0.1506</td>\n",
              "      <td>0.06009</td>\n",
              "      <td>0.3478</td>\n",
              "      <td>1.0180</td>\n",
              "      <td>2.749</td>\n",
              "      <td>31.01</td>\n",
              "      <td>0.004107</td>\n",
              "      <td>0.03288</td>\n",
              "      <td>0.02821</td>\n",
              "      <td>0.013500</td>\n",
              "      <td>0.01610</td>\n",
              "      <td>0.002744</td>\n",
              "      <td>16.45</td>\n",
              "      <td>27.26</td>\n",
              "      <td>112.10</td>\n",
              "      <td>828.5</td>\n",
              "      <td>0.1153</td>\n",
              "      <td>0.3429</td>\n",
              "      <td>0.2512</td>\n",
              "      <td>0.13390</td>\n",
              "      <td>0.2534</td>\n",
              "      <td>0.07858</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "134        18.45         21.91  ...          0.3109                  0.07610\n",
              "279        13.85         15.18  ...          0.2955                  0.06912\n",
              "277        18.81         19.98  ...          0.2567                  0.05737\n",
              "156        17.68         20.74  ...          0.2463                  0.07738\n",
              "476        14.20         20.53  ...          0.2534                  0.07858\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 404,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 405,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "iB3dndVFzSjT",
        "outputId": "044ef5a0-2092-4990-f0fa-30c2fe15fc12"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>17.270</td>\n",
              "      <td>25.42</td>\n",
              "      <td>112.40</td>\n",
              "      <td>928.8</td>\n",
              "      <td>0.08331</td>\n",
              "      <td>0.11090</td>\n",
              "      <td>0.12040</td>\n",
              "      <td>0.05736</td>\n",
              "      <td>0.1467</td>\n",
              "      <td>0.05407</td>\n",
              "      <td>0.5100</td>\n",
              "      <td>1.6790</td>\n",
              "      <td>3.283</td>\n",
              "      <td>58.38</td>\n",
              "      <td>0.008109</td>\n",
              "      <td>0.043080</td>\n",
              "      <td>0.04942</td>\n",
              "      <td>0.01742</td>\n",
              "      <td>0.01594</td>\n",
              "      <td>0.003739</td>\n",
              "      <td>20.380</td>\n",
              "      <td>35.46</td>\n",
              "      <td>132.80</td>\n",
              "      <td>1284.0</td>\n",
              "      <td>0.1436</td>\n",
              "      <td>0.4122</td>\n",
              "      <td>0.50360</td>\n",
              "      <td>0.17390</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.07944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>7.729</td>\n",
              "      <td>25.49</td>\n",
              "      <td>47.98</td>\n",
              "      <td>178.8</td>\n",
              "      <td>0.08098</td>\n",
              "      <td>0.04878</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1870</td>\n",
              "      <td>0.07285</td>\n",
              "      <td>0.3777</td>\n",
              "      <td>1.4620</td>\n",
              "      <td>2.492</td>\n",
              "      <td>19.14</td>\n",
              "      <td>0.012660</td>\n",
              "      <td>0.009692</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02882</td>\n",
              "      <td>0.006872</td>\n",
              "      <td>9.077</td>\n",
              "      <td>30.92</td>\n",
              "      <td>57.17</td>\n",
              "      <td>248.0</td>\n",
              "      <td>0.1256</td>\n",
              "      <td>0.0834</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.3058</td>\n",
              "      <td>0.09938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>14.870</td>\n",
              "      <td>16.67</td>\n",
              "      <td>98.64</td>\n",
              "      <td>682.5</td>\n",
              "      <td>0.11620</td>\n",
              "      <td>0.16490</td>\n",
              "      <td>0.16900</td>\n",
              "      <td>0.08923</td>\n",
              "      <td>0.2157</td>\n",
              "      <td>0.06768</td>\n",
              "      <td>0.4266</td>\n",
              "      <td>0.9489</td>\n",
              "      <td>2.989</td>\n",
              "      <td>41.18</td>\n",
              "      <td>0.006985</td>\n",
              "      <td>0.025630</td>\n",
              "      <td>0.03011</td>\n",
              "      <td>0.01271</td>\n",
              "      <td>0.01602</td>\n",
              "      <td>0.003884</td>\n",
              "      <td>18.810</td>\n",
              "      <td>27.37</td>\n",
              "      <td>127.10</td>\n",
              "      <td>1095.0</td>\n",
              "      <td>0.1878</td>\n",
              "      <td>0.4480</td>\n",
              "      <td>0.47040</td>\n",
              "      <td>0.20270</td>\n",
              "      <td>0.3585</td>\n",
              "      <td>0.10650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>11.410</td>\n",
              "      <td>10.82</td>\n",
              "      <td>73.34</td>\n",
              "      <td>403.3</td>\n",
              "      <td>0.09373</td>\n",
              "      <td>0.06685</td>\n",
              "      <td>0.03512</td>\n",
              "      <td>0.02623</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.06113</td>\n",
              "      <td>0.1408</td>\n",
              "      <td>0.4607</td>\n",
              "      <td>1.103</td>\n",
              "      <td>10.50</td>\n",
              "      <td>0.006040</td>\n",
              "      <td>0.015290</td>\n",
              "      <td>0.01514</td>\n",
              "      <td>0.00646</td>\n",
              "      <td>0.01344</td>\n",
              "      <td>0.002206</td>\n",
              "      <td>12.820</td>\n",
              "      <td>15.97</td>\n",
              "      <td>83.74</td>\n",
              "      <td>510.5</td>\n",
              "      <td>0.1548</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.21020</td>\n",
              "      <td>0.08958</td>\n",
              "      <td>0.3016</td>\n",
              "      <td>0.08523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>9.504</td>\n",
              "      <td>12.44</td>\n",
              "      <td>60.34</td>\n",
              "      <td>273.9</td>\n",
              "      <td>0.10240</td>\n",
              "      <td>0.06492</td>\n",
              "      <td>0.02956</td>\n",
              "      <td>0.02076</td>\n",
              "      <td>0.1815</td>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.2773</td>\n",
              "      <td>0.9768</td>\n",
              "      <td>1.909</td>\n",
              "      <td>15.70</td>\n",
              "      <td>0.009606</td>\n",
              "      <td>0.014320</td>\n",
              "      <td>0.01985</td>\n",
              "      <td>0.01421</td>\n",
              "      <td>0.02027</td>\n",
              "      <td>0.002968</td>\n",
              "      <td>10.230</td>\n",
              "      <td>15.66</td>\n",
              "      <td>65.13</td>\n",
              "      <td>314.9</td>\n",
              "      <td>0.1324</td>\n",
              "      <td>0.1148</td>\n",
              "      <td>0.08867</td>\n",
              "      <td>0.06227</td>\n",
              "      <td>0.2450</td>\n",
              "      <td>0.07773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "441       17.270         25.42  ...          0.2500                  0.07944\n",
              "538        7.729         25.49  ...          0.3058                  0.09938\n",
              "117       14.870         16.67  ...          0.3585                  0.10650\n",
              "120       11.410         10.82  ...          0.3016                  0.08523\n",
              "21         9.504         12.44  ...          0.2450                  0.07773\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 405,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 406,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "CzDbJRU_za32",
        "outputId": "48cb15c5-4e84-4ae3-bc9b-8e33bbfe159f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "134  0\n",
              "279  1\n",
              "277  0\n",
              "156  0\n",
              "476  1\n",
              "..  ..\n",
              "3    0\n",
              "522  1\n",
              "211  1\n",
              "188  1\n",
              "175  1\n",
              "\n",
              "[398 rows x 1 columns]"
            ]
          },
          "execution_count": 406,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 407,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "zEReh4TAzeYd",
        "outputId": "c192ad57-c865-4364-d8cf-e76b0a28d0c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>171 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0\n",
              "441  0\n",
              "538  1\n",
              "117  0\n",
              "120  1\n",
              "21   1\n",
              "..  ..\n",
              "367  1\n",
              "458  1\n",
              "109  1\n",
              "384  1\n",
              "124  1\n",
              "\n",
              "[171 rows x 1 columns]"
            ]
          },
          "execution_count": 407,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0MBby1vdB-Q"
      },
      "source": [
        "SCATTER PLOT FOR 3 FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 408,
      "metadata": {
        "id": "q-cMelUasU5_"
      },
      "outputs": [],
      "source": [
        "#Scatter plot of X_Train vs Y_Train (while X_Train containing a single feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YLpVHGyVJBPd",
        "outputId": "61270893-9624-435f-dd21-f387cb1a8944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<matplotlib.collections.PathCollection object at 0x7f4d0e537a10>\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(plt.scatter(X_Train.iloc[:,0],Y_Train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 410,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "85Cg_LqXJBvK",
        "outputId": "2acf450e-df99-421d-8ea5-df8cb000adb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<matplotlib.collections.PathCollection object at 0x7f4d0e537d50>\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(plt.scatter(X_Train.iloc[:,1],Y_Train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "lSyNhIzxJCHW",
        "outputId": "38a00fcd-b983-472a-f75d-12527d88d472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<matplotlib.collections.PathCollection object at 0x7f4d0e510f50>\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUR0lEQVR4nO3df5Ac513n8fdXo5G9MuC1ozXglYwUl2LOYBw5e7Yo8yMkASsmJ+lCcrEqLsgR4iKQ1F2SMmWTlAETKiSigFDnI+fL5SD8sDEmGB1nShxgjirqZLyKYzu2IyJkE0kOeONEriNW4rX05Y/uXc+OZnZmVyPN6PH7VbWl6aef7v7q6Z7PznT37ERmIkk6860YdgGSpMEw0CWpEAa6JBXCQJekQhjoklSIlcPa8Jo1a3L9+vXD2rwknZH27t37pcyc6DRvaIG+fv16pqenh7V5STojRcQ/dpvnKRdJKoSBLkmFMNAlqRAGuiQVwkCXpEL0vMslIj4BvAF4OjO/s8P8AD4KXAs8B7wtMz896EIB7nnwMDt37+OpI0e5cHyMG6+5hO2bJpfcp9N6b/7UwxydPT7f1lwB33B2kyPPzc6v57b7Ps/nn/7qqfivveSdt7rJz/2771iwr9r35fqXjbHnwFc4lkkjgpdPrObAzHPz05tffh5PPnN0SfteKkn0+muLEfF9wL8An+wS6NcC76YK9KuAj2bmVb02PDU1lUu5bbEK3Uc4Ontsvm2s2eBDb7xs/knbT59O633vH3yG4x3nvigA/y7lqdVsBDvfdDnbN0123JdL1WvfS2eiiNibmVOd5vU85ZKZfwN8eZEu26jCPjNzDzAeEd+6vFK727l73wlP7qOzx9i5e9+S+nRab68wB8P8dJg9lvP7qtO+XKpe+14qzSDOoU8CB1umD9VtJ4iIGyJiOiKmZ2ZmlrSRp44c7dneT5+lzNPpN7c/BrVf3L96KTmtF0Uz8/bMnMrMqYmJjp9c7erC8bGe7f30Wco8nX5z+2NQ+8X9q5eSQQT6YWBdy/Taum2gbrzmEsaajQVtY80GN15zyZL6dFpvP4MQS6pWy9FsxPy+6rQvl6rXvpdKM4hA3wX8aFQ2A89m5hcHsN4Ftm+a5ENvvIzJ8TECmBwfO+GCVz99Oq33V9/ySsaaC4eiuaK682JuPb/2lley8YJzBv3fUu281c35C6LQeV9effH5NKL61dqIYOMF5yyYvvri85e076XS9HOXyx3Aq4E1wD8DPwc0ATLzY/Vti/8F2EJ12+J/zMyet68s9S4XSdLid7n0vA89M3f0mJ/ATy+zNknSgPhJUUkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCtFXoEfElojYFxH7I+KmDvMvioj7IuLBiHg4Iq4dfKmSpMX0DPSIaAC3Aa8HLgV2RMSlbd0+ANyVmZuA64D/OuhCJUmL6+cV+pXA/sw8kJnPA3cC29r6JPBN9eNzgacGV6IkqR/9BPokcLBl+lDd1urngesj4hBwL/DuTiuKiBsiYjoipmdmZpZRriSpm0FdFN0B/FZmrgWuBX4nIk5Yd2benplTmTk1MTExoE1LkqC/QD8MrGuZXlu3tXo7cBdAZv4/4GxgzSAKlCT1p59AfwDYGBEbImIV1UXPXW19vgC8FiAi/g1VoHtORZJOo56BnpkvAO8CdgOPU93N8mhE3BoRW+tu7wPeEREPAXcAb8vMPFVFS5JOtLKfTpl5L9XFzta2W1oePwZcPdjSJElL4SdFJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiH6CvSI2BIR+yJif0Tc1KXPf4iIxyLi0Yj4/cGWKUnqZWWvDhHRAG4DfhA4BDwQEbsy87GWPhuBm4GrM/MrEXHBqSpYktRZP6/QrwT2Z+aBzHweuBPY1tbnHcBtmfkVgMx8erBlSpJ66SfQJ4GDLdOH6rZWrwBeERF/GxF7ImJLpxVFxA0RMR0R0zMzM8urWJLU0aAuiq4ENgKvBnYA/z0ixts7ZebtmTmVmVMTExMD2rQkCfoL9MPAupbptXVbq0PArsyczcwngL+nCnhJ0mnST6A/AGyMiA0RsQq4DtjV1uceqlfnRMQaqlMwBwZYpySph56BnpkvAO8CdgOPA3dl5qMRcWtEbK277QaeiYjHgPuAGzPzmVNVtCTpRJGZQ9nw1NRUTk9PD2XbknSmioi9mTnVaZ6fFJWkQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRB9BXpEbImIfRGxPyJuWqTfj0RERsTU4EqUJPWjZ6BHRAO4DXg9cCmwIyIu7dDvG4H/BNw/6CIlSb318wr9SmB/Zh7IzOeBO4FtHfr9IvBh4GsDrE+S1Kd+An0SONgyfahumxcRVwDrMvN/L7aiiLghIqYjYnpmZmbJxUqSujvpi6IRsQL4VeB9vfpm5u2ZOZWZUxMTEye7aUlSi34C/TCwrmV6bd025xuB7wT+OiKeBDYDu7wwKkmnVz+B/gCwMSI2RMQq4Dpg19zMzHw2M9dk5vrMXA/sAbZm5vQpqViS1FHPQM/MF4B3AbuBx4G7MvPRiLg1Irae6gIlSf1Z2U+nzLwXuLet7ZYufV998mVJkpbKT4pKUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQvQV6BGxJSL2RcT+iLipw/z3RsRjEfFwRPxlRHzb4EuVJC2mZ6BHRAO4DXg9cCmwIyIubev2IDCVmd8F3A18ZNCFSpIW188r9CuB/Zl5IDOfB+4EtrV2yMz7MvO5enIPsHawZUqSeukn0CeBgy3Th+q2bt4O/FmnGRFxQ0RMR8T0zMxM/1VKknoa6EXRiLgemAJ2dpqfmbdn5lRmTk1MTAxy05L0kreyjz6HgXUt02vrtgUi4nXA+4Hvz8yvD6Y8SVK/+nmF/gCwMSI2RMQq4DpgV2uHiNgE/Ddga2Y+PfgyJUm99Az0zHwBeBewG3gcuCszH42IWyNia91tJ/ANwB9GxGciYleX1UmSTpF+TrmQmfcC97a13dLy+HUDrkuStER+UlSSCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEKs7KdTRGwBPgo0gI9n5i+3zT8L+CTwKuAZ4C2Z+eRgS33puufBw+zcvY+njhzlwvExbrzmErZvmjyhzy/8r0f5ynOzAIyPNfn5rd+xoF+n9QDzbatXNfjq88d61nPOqgbHMzk6e3xB++rmCmaPHaetGYCrLz6fJ585yuEjR7uuN4AEVgQ0go7raTU+1uT/f22WY/li2wqgx2KLCuCtmy/iiZl/4W//4csnsabToxHByydWc2DmOY7liwMx2bZ/Dx85yoqA47lw+QjIfLH/9k2TfOCeR7jj/oMcy6QRwY6r1vHB7ZedsO3Wfq3Gmis4u9ngyHOzHY/Xfo7nTuaWO3zkKI0IjmUuqHuxZdq3tdwalvp/aO/3A98+wX2fm1n2dnuJbNsZJ3SIaAB/D/wgcAh4ANiRmY+19Pkp4Lsy8ycj4jrg32fmWxZb79TUVE5PT59s/cW758HD3PypRzg6+2LQjjUbfOiNl80fCPc8eJgb736I2WML92VzRbDzzZfPH8Dt62muCAhOWE5lWOr+HWs2uOKiczv+Irt+80ULQv0D9zzC7+75Qt/rnTte+zmeO+m0XK/lu23rR141yR/tPbzkGnqtt335xWpeznbnRMTezJzqNK+fUy5XAvsz80BmPg/cCWxr67MN+O368d3AayMi+q5QXe3cve+EA+Lo7DF27t63oE+nJ+3s8Zzv12k9s8fTMC/YUvfv0dljXd+V3HH/wUWne613seOw/XjupNNyvZbvtq077j+4rBp6rbd9+cVqXs52+9FPoE8CrXvvUN3WsU9mvgA8C7ysfUURcUNETEfE9MzMzPIqfol5qsspitb2bn1a5y3WR+ql/bRK+3QvvY7DXsfncuZ3W6Zb7f0+R/r9P5zs+pbjtF4UzczbM3MqM6cmJiZO56bPWBeOj/Vs79andd5ifaReGm1vuNune+l1HPY6Ppczv9sy3Wrv9znS7//hZNe3HP0E+mFgXcv02rqtY5+IWAmcS3VxVCfpxmsuYazZWNA21mzMX/Ca69NsnHiQNlfEfL9O62muiI7LqQxL3b9jzQZXX3x+x3k7rlq36HSv9S52HLYfz510Wq7X8t22teOqdcuqodd625dfrOblbLcf/QT6A8DGiNgQEauA64BdbX12AT9WP34T8FfZ62qr+rJ90yQfeuNlTI6PEVR3I7RfRNm+aZKdb7qc81Y359vGx5rzF0S7rWfnmy9n55sun287Z9XiB9+cc1Y1GGueeOisbq6gQzNQ3eUy2eOVyFz0rAi6rqfV+FiT9rw62becQXUBsFuwjZpGBBsvOOeEV53t+xeqcW03t9jccfV77/hurt980fz6GhEnXBAF+OD2yxb0azXWXMF5q5sdj9d+judOWpebq6u17k7Ld9vWB7dftqwaeq23fflO/a7ffNGyt9uPnne5AETEtcCvU922+InM/KWIuBWYzsxdEXE28DvAJuDLwHWZeWCxdXqXiyQt3WJ3ufR1H3pm3gvc29Z2S8vjrwFvPpkiJUknx0+KSlIhDHRJKoSBLkmFMNAlqRB93eVySjYcMQP8Y5fZa4AvncZylss6B+9MqdU6B8s6+/dtmdnxk5lDC/TFRMR0t9tyRol1Dt6ZUqt1DpZ1DoanXCSpEAa6JBViVAP99mEX0CfrHLwzpVbrHCzrHICRPIcuSVq6UX2FLklaIgNdkgoxMoEeEY2IeDAi/rSe3hAR90fE/oj4g/pP9w67xvGIuDsiPhcRj0fEd0fE+RHxfyLi8/W/541Ane+JiEcj4rMRcUdEnD0K4xkRn4iIpyPisy1tHccvKr9R1/twRFwx5Dp31vv94Yj444gYb5l3c13nvoi4Zph1tsx7X0RkRKypp0dqPOv2d9dj+mhEfKSlfWTGMyJeGRF7IuIz9betXVm3D208F5WZI/EDvBf4feBP6+m7qP4ML8DHgHeOQI2/DfxE/XgVMA58BLipbrsJ+PCQa5wEngDGWsbxbaMwnsD3AVcAn21p6zh+wLXAn1H9ifLNwP1DrvOHgJX14w+31Hkp8BBwFrAB+AegMaw66/Z1wG6qD+6tGdHx/AHgL4Cz6ukLRnE8gT8HXt8yhn897PFc7GckXqFHxFrgh4GP19MBvIbqC6ehCtLtw6muEhHnUu3w/wGQmc9n5hEWfkH20OusrQTG6m+PWg18kREYz8z8G6q/l9+q2/htAz6ZlT3AeER867DqzMw/z+r7cgH2UH1z11ydd2bm1zPzCWA/1RerD6XO2q8BPwO03vEwUuMJvBP45cz8et3n6ZY6R2k8E/im+vG5wFMtdQ5lPBczEoFO9eUZPwMcr6dfBhxpeQJ1+mLq020DMAP8z/rU0Mcj4hzgmzPzi3WffwK+eWgVApl5GPgV4AtUQf4ssJfRG8853cavny8nH5Yfp3p1BiNWZ0RsAw5n5kNts0aqTuAVwPfWpwH/b0T827p91Or8z8DOiDhI9by6uW4ftTqBEQj0iHgD8HRm7h12LT2spHo79puZuQn4KtUpgnlZvRcb6n2g9TnobVS/gC4EzgG2DLOmfo3C+PUSEe8HXgB+b9i1tIuI1cDPArf06jsCVgLnU52uuBG4q35nPmreCbwnM9cB76F+hz6qhh7owNXA1oh4EriT6tTAR6newsx9o1KnL6Y+3Q4BhzLz/nr6bqqA/+e5t1r1v093Wf50eR3wRGbOZOYs8CmqMR618ZzTbfz6+XLy0yoi3ga8AXhr/csHRqvOi6l+kT9UP5/WAp+OiG9htOqE6vn0qfqUxd9RvTtfw+jV+WNUzyGAP+TF0z+jVicwAoGemTdn5trMXE/1BdR/lZlvBe6j+sJpqAb1T4ZUIgCZ+U/AwYiY+4ru1wKPsfALsodeJ9Wpls0Rsbp+xTNX50iNZ4tu47cL+NH6boLNwLMtp2ZOu4jYQnVacGtmPtcyaxdwXUScFREbgI3A3w2jxsx8JDMvyMz19fPpEHBFfeyO1HgC91BdGCUiXkF1k8GXGKHxrD0FfH/9+DXA5+vHozaelWFflW39AV7Ni3e5vJxqR+6n+s141gjU90pgGniY6oA8j+p8/19S7ei/AM4fgTp/Afgc8FmqL+8+axTGE7iD6rz+LFXYvL3b+FHdPXAb1V0OjwBTQ65zP9U508/UPx9r6f/+us591HdEDKvOtvlP8uJdLqM2nquA362P0U8DrxnF8QS+h+oa1EPA/cCrhj2ei/340X9JKsTQT7lIkgbDQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmF+FcpmrhyY7GICQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(plt.scatter(X_Train.iloc[:,2],Y_Train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKL-IE5dzgi3",
        "outputId": "1e227227-cd3d-437c-eb32-3baafa42dd4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _breast_cancer_dataset:\n",
            "\n",
            "Breast cancer wisconsin (diagnostic) dataset\n",
            "--------------------------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 569\n",
            "\n",
            "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
            "\n",
            "    :Attribute Information:\n",
            "        - radius (mean of distances from center to points on the perimeter)\n",
            "        - texture (standard deviation of gray-scale values)\n",
            "        - perimeter\n",
            "        - area\n",
            "        - smoothness (local variation in radius lengths)\n",
            "        - compactness (perimeter^2 / area - 1.0)\n",
            "        - concavity (severity of concave portions of the contour)\n",
            "        - concave points (number of concave portions of the contour)\n",
            "        - symmetry \n",
            "        - fractal dimension (\"coastline approximation\" - 1)\n",
            "\n",
            "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
            "        largest values) of these features were computed for each image,\n",
            "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
            "        13 is Radius SE, field 23 is Worst Radius.\n",
            "\n",
            "        - class:\n",
            "                - WDBC-Malignant\n",
            "                - WDBC-Benign\n",
            "\n",
            "    :Summary Statistics:\n",
            "\n",
            "    ===================================== ====== ======\n",
            "                                           Min    Max\n",
            "    ===================================== ====== ======\n",
            "    radius (mean):                        6.981  28.11\n",
            "    texture (mean):                       9.71   39.28\n",
            "    perimeter (mean):                     43.79  188.5\n",
            "    area (mean):                          143.5  2501.0\n",
            "    smoothness (mean):                    0.053  0.163\n",
            "    compactness (mean):                   0.019  0.345\n",
            "    concavity (mean):                     0.0    0.427\n",
            "    concave points (mean):                0.0    0.201\n",
            "    symmetry (mean):                      0.106  0.304\n",
            "    fractal dimension (mean):             0.05   0.097\n",
            "    radius (standard error):              0.112  2.873\n",
            "    texture (standard error):             0.36   4.885\n",
            "    perimeter (standard error):           0.757  21.98\n",
            "    area (standard error):                6.802  542.2\n",
            "    smoothness (standard error):          0.002  0.031\n",
            "    compactness (standard error):         0.002  0.135\n",
            "    concavity (standard error):           0.0    0.396\n",
            "    concave points (standard error):      0.0    0.053\n",
            "    symmetry (standard error):            0.008  0.079\n",
            "    fractal dimension (standard error):   0.001  0.03\n",
            "    radius (worst):                       7.93   36.04\n",
            "    texture (worst):                      12.02  49.54\n",
            "    perimeter (worst):                    50.41  251.2\n",
            "    area (worst):                         185.2  4254.0\n",
            "    smoothness (worst):                   0.071  0.223\n",
            "    compactness (worst):                  0.027  1.058\n",
            "    concavity (worst):                    0.0    1.252\n",
            "    concave points (worst):               0.0    0.291\n",
            "    symmetry (worst):                     0.156  0.664\n",
            "    fractal dimension (worst):            0.055  0.208\n",
            "    ===================================== ====== ======\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
            "\n",
            "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
            "\n",
            "    :Donor: Nick Street\n",
            "\n",
            "    :Date: November, 1995\n",
            "\n",
            "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
            "https://goo.gl/U2Uwz2\n",
            "\n",
            "Features are computed from a digitized image of a fine needle\n",
            "aspirate (FNA) of a breast mass.  They describe\n",
            "characteristics of the cell nuclei present in the image.\n",
            "\n",
            "Separating plane described above was obtained using\n",
            "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
            "Construction Via Linear Programming.\" Proceedings of the 4th\n",
            "Midwest Artificial Intelligence and Cognitive Science Society,\n",
            "pp. 97-101, 1992], a classification method which uses linear\n",
            "programming to construct a decision tree.  Relevant features\n",
            "were selected using an exhaustive search in the space of 1-4\n",
            "features and 1-3 separating planes.\n",
            "\n",
            "The actual linear program used to obtain the separating plane\n",
            "in the 3-dimensional space is that described in:\n",
            "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
            "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
            "Optimization Methods and Software 1, 1992, 23-34].\n",
            "\n",
            "This database is also available through the UW CS ftp server:\n",
            "\n",
            "ftp ftp.cs.wisc.edu\n",
            "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
            "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
            "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
            "     San Jose, CA, 1993.\n",
            "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
            "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
            "     July-August 1995.\n",
            "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
            "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
            "     163-171.\n"
          ]
        }
      ],
      "source": [
        "print(cancer.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "gGEREkAosvvG",
        "outputId": "7abff39e-09fa-42ab-d66e-d21be651c762"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'StandardScaler--standardizes a feature by subtracting the mean and then scaling to unit variance. \\n   Unit variance means dividing all the values by the standard deviation.\\n   StandardScaler makes the mean of the distribution 0'"
            ]
          },
          "execution_count": 413,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#sklearn.preprocessing is a package\n",
        "\"\"\"StandardScaler--\"\"\" \"\"\"standardizes a feature by subtracting the mean and then scaling to unit variance. \n",
        "   Unit variance means dividing all the values by the standard deviation.\n",
        "   StandardScaler makes the mean of the distribution 0\"\"\"\n",
        "\n",
        "#fit_transform : used on the training data so that we can scale the training data and also learn the scaling parameters of that data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egMLpzJVzjMM",
        "outputId": "de5e12b1-76af-427a-d790-db2b9c11bf3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.1606914   0.65987744  1.09116807 ...  0.33447214  0.34027725\n",
            "  -0.43837415]\n",
            " [-0.08999652 -0.9815372  -0.13507158 ... -0.22454104  0.09243676\n",
            "  -0.82173332]\n",
            " [ 1.25857133  0.18915972  1.11867104 ...  0.20933092 -0.53199254\n",
            "  -1.4670729 ]\n",
            " ...\n",
            " [-0.63649276 -0.06449128 -0.66470023 ... -0.67799392 -0.58349186\n",
            "  -0.2280209 ]\n",
            " [-0.64464942 -0.44252883 -0.67412982 ... -1.06180939  0.48672845\n",
            "  -1.00627298]\n",
            " [-1.49810798 -1.15958069 -1.49332548 ... -1.69576008 -0.49175869\n",
            "  -0.30765856]]\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "[[ 1.04684614  1.25721011  1.01136447 ...  1.00895794 -0.66864785\n",
            "  -0.23725838]\n",
            " [-2.00970194  1.27204573 -2.01913883 ... -1.88481567  0.24540717\n",
            "   0.89195267]\n",
            " [ 0.27798382 -0.59724204  0.36405424 ...  1.4882028   1.10868135\n",
            "   1.29516143]\n",
            " ...\n",
            " [-0.85288451  0.37555057 -0.8665879  ... -0.50731953 -0.12971577\n",
            "   0.26561996]\n",
            " [-0.23138747 -1.22245734 -0.24044697 ... -0.35838753 -0.28205827\n",
            "  -0.59063234]\n",
            " [-0.20255513 -0.65658451 -0.22586367 ... -0.3908364  -1.40906517\n",
            "  -0.41621058]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "standard=StandardScaler()\n",
        "X_Train=standard.fit_transform(X_Train)\n",
        "X_Test=standard.fit_transform(X_Test)\n",
        "\n",
        "print(X_Train)\n",
        "print(\"----\"*50)\n",
        "print(X_Test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ppX-C_NVeY5"
      },
      "source": [
        "MODELS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8aL57KgghGc"
      },
      "source": [
        "Classifier: An algorithm that maps the input data to a specific category.\n",
        "\n",
        "\n",
        "Classification model: A classification model tries to draw some conclusion from the input values given for training. It will predict the class labels/categories for the new data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "id": "WGwa-U6Th-36"
      },
      "outputs": [],
      "source": [
        "#Definition: Random forest classifier is a meta-estimator that fits a number of decision trees on various sub-samples of datasets and uses average to improve the predictive accuracy of the model and controls over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement.\n",
        "\n",
        "#Advantages: Reduction in over-fitting and random forest classifier is more accurate than decision trees in most cases.\n",
        "\n",
        "#Disadvantages: Slow real time prediction, difficult to implement, and complex algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpDGRcyF0Ute",
        "outputId": "abd22390-68e5-402f-9e14-9e921684dfc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
            "                       n_jobs=None, oob_score=False, random_state=80, verbose=0,\n",
            "                       warm_start=False)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classification_rfc=RandomForestClassifier(n_estimators=10, criterion=\"entropy\",random_state=80)\n",
        "print(classification_rfc.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "id": "V7mtZh1QhyBA"
      },
      "outputs": [],
      "source": [
        "#Definition: Given a data of attributes together with its classes, a decision tree produces a sequence of rules that can be used to classify the data.\n",
        "\n",
        "#Advantages: Decision Tree is simple to understand and visualise, requires little data preparation, and can handle both numerical and categorical data.\n",
        "\n",
        "#Disadvantages: Decision tree can create complex trees that do not generalise well, and decision trees can be unstable because small variations in the data might result in a completely different tree being generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQMsDclB3phF",
        "outputId": "07cde684-19a1-4a5b-bf84-520db9af719b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=80, splitter='best')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classification_dtc=DecisionTreeClassifier(criterion=\"entropy\",random_state=80)\n",
        "print(classification_dtc.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 419,
      "metadata": {
        "id": "UxQJXzVohNb6"
      },
      "outputs": [],
      "source": [
        "#Definition: Logistic regression is a machine learning algorithm for classification. In this algorithm, the probabilities describing the possible outcomes of a single trial are modelled using a logistic function.\n",
        "\n",
        "#Advantages: Logistic regression is designed for this purpose (classification), and is most useful for understanding the influence of several independent variables on a single outcome variable.\n",
        "\n",
        "#Disadvantages: Works only when the predicted variable is binary, assumes all predictors are independent of each other and assumes data is free of missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 420,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjKA8r9gGvCb",
        "outputId": "fb6bda6e-bd41-4b79-d36e-c392067c6272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classification_log=LogisticRegression()\n",
        "print(classification_log.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 421,
      "metadata": {
        "id": "oDKNwtAthWYG"
      },
      "outputs": [],
      "source": [
        "#Definition: Neighbours based classification is a type of lazy learning as it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the k nearest neighbours of each point.\n",
        "\n",
        "#Advantages: This algorithm is simple to implement, robust to noisy training data, and effective if training data is large.\n",
        "\n",
        "#Disadvantages: Need to determine the value of K and the computation cost is high as it needs to compute the distance of each instance to all the training samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06p-aSivGyS0",
        "outputId": "6b4ab052-7303-4cbf-c26b-a9b4d4e34f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classification_knn=KNeighborsClassifier()\n",
        "print(classification_knn.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "RBZ2hXX6hiIf"
      },
      "outputs": [],
      "source": [
        "#Definition: Naive Bayes algorithm based on Bayes’ theorem with the assumption of independence between every pair of features. Naive Bayes classifiers work well in many real-world situations such as document classification and spam filtering.\n",
        "\n",
        "#Advantages: This algorithm requires a small amount of training data to estimate the necessary parameters. Naive Bayes classifiers are extremely fast compared to more sophisticated methods.\n",
        "\n",
        "#Disadvantages: Naive Bayes is is known to be a bad estimator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd4lld5Zs3UI",
        "outputId": "4dd2006a-a374-4c4a-a81d-f1086bbf92ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GaussianNB(priors=None, var_smoothing=1e-09)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "classification_gnb=GaussianNB()\n",
        "print(classification_gnb.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "id": "24EmsKP-iJqv"
      },
      "outputs": [],
      "source": [
        "#Definition: Support vector machine is a representation of the training data as points in space separated into categories by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
        "\n",
        "#Advantages: Effective in high dimensional spaces and uses a subset of training points in the decision function so it is also memory efficient.\n",
        "\n",
        "#Disadvantages: The algorithm does not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDvJMy0ztVzq",
        "outputId": "0e9efad3-44ea-4f55-b8f2-248716150e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=80, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "classification_svc=SVC(kernel=\"linear\",random_state=80)\n",
        "print(classification_svc.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "id": "RZGNtIv2jXnV"
      },
      "outputs": [],
      "source": [
        "#Definition: Multinomial Naive Bayes algorithm is a probabilistic learning method that is mostly used in Natural Language Processing (NLP).The algorithm is based on the Bayes theorem and predicts the tag of a text such as a piece of email or newspaper article. It calculates the probability of each tag for a given sample and then gives the tag with the highest probability as output.\n",
        "\n",
        "#Advantages: It is easy to implement as you only have to calculate probability.\n",
        "# You can use this algorithm on both continuous and discrete data.\n",
        "# It is simple and can be used for predicting real-time applications.\n",
        "# It is highly scalable and can easily handle large datasets.\n",
        "\n",
        "#Disadvantages:The prediction accuracy of this algorithm is lower than the other probability algorithms.\n",
        "# It is not suitable for regression. Naive Bayes algorithm is only used for textual data classification and cannot be used to predict numeric values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djg9eDzUtzyK",
        "outputId": "233fc65e-f975-4058-f0dc-9ef87dc6e94f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "classification_mnb=MultinomialNB(alpha=1.0,class_prior=None,fit_prior=True)\n",
        "# MinMaxScaler() to preprocess the data before sending the data to the model. This normalizes it to the range 0 to 1 thus removing the negative numbers.\n",
        "scaler = MinMaxScaler()\n",
        "X_Train = scaler.fit_transform(X_Train)\n",
        "Y_Test = scaler.fit_transform(Y_Test)\n",
        "# nb_model=Pipeline(steps=[('preprocessor',preprocessorForFeatures),('classifier',nbClassifier)])\n",
        "print(classification_mnb.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "id": "0mEb5Nu4kJsr"
      },
      "outputs": [],
      "source": [
        "#Definition: Linear discriminant analysis (LDA) is a type of linear combination, a mathematical process using various data items and applying functions to that set to separately analyze multiple classes of objects or items.\n",
        "\n",
        "#Advantages: It's fast · It's intuitive · It can predict topics for new unseen documents.\n",
        "\n",
        "#Disadvantages: It requires normal distribution assumption on features/predictors.Sometimes not good for few categories variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 430,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EGbEAhRvwoo",
        "outputId": "643834ea-1caa-469c-dcfc-f2c4a923dec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LinearDiscriminantAnalysis(n_components=1, priors=None, shrinkage=None,\n",
            "                           solver='svd', store_covariance=False, tol=0.0001)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "classification_lda = LDA(n_components=1)\n",
        "print(classification_lda.fit(X_Train,Y_Train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "id": "_kDxqcXG6iH0"
      },
      "outputs": [],
      "source": [
        "#List of the models\n",
        "\n",
        "classification_list=[classification_svc,classification_dtc,classification_gnb,classification_knn,classification_lda,classification_log,classification_mnb,classification_rfc]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-poDNh4wVsQM"
      },
      "source": [
        "CALCULATE ACCURACY, CLASSIFICATION REPORT AND CONFUSION MATRIX "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZIRbFrQIlpe",
        "outputId": "c31a7515-61df-4883-8507-a1e3cd6bab1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier:\n",
            " SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
            "    max_iter=-1, probability=False, random_state=80, shrinking=True, tol=0.001,\n",
            "    verbose=False)\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    95.32163742690058\n",
            "BALANCED ACCURACY SCORE:    95.36693318103941\n",
            "f1 SCORE:    96.07843137254902 \n",
            "\n",
            "\n",
            "\n",
            "95.32163742690058\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.93      0.94        70\n",
            "         1.0       0.95      0.97      0.96       101\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.95      0.95      0.95       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[65  5]\n",
            " [ 3 98]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Classifier:\n",
            " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=80, splitter='best')\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    91.81286549707602\n",
            "BALANCED ACCURACY SCORE:    91.92640692640693\n",
            "f1 SCORE:    93.20388349514563 \n",
            "\n",
            "\n",
            "\n",
            "91.81286549707602\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.87      0.90        70\n",
            "         1.0       0.91      0.95      0.93       101\n",
            "\n",
            "    accuracy                           0.92       171\n",
            "   macro avg       0.92      0.91      0.91       171\n",
            "weighted avg       0.92      0.92      0.92       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[61  9]\n",
            " [ 5 96]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Classifier:\n",
            " GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    93.56725146198829\n",
            "BALANCED ACCURACY SCORE:    93.43563512361466\n",
            "f1 SCORE:    94.58128078817734 \n",
            "\n",
            "\n",
            "\n",
            "93.56725146198829\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.91      0.92        70\n",
            "         1.0       0.94      0.95      0.95       101\n",
            "\n",
            "    accuracy                           0.94       171\n",
            "   macro avg       0.93      0.93      0.93       171\n",
            "weighted avg       0.94      0.94      0.94       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[64  6]\n",
            " [ 5 96]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Classifier:\n",
            " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    95.32163742690058\n",
            "BALANCED ACCURACY SCORE:    95.94772196261682\n",
            "f1 SCORE:    96.15384615384615 \n",
            "\n",
            "\n",
            "\n",
            "95.32163742690058\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.90      0.94        70\n",
            "         1.0       0.93      0.99      0.96       101\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.96      0.95      0.95       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 63   7]\n",
            " [  1 100]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Classifier:\n",
            " LinearDiscriminantAnalysis(n_components=1, priors=None, shrinkage=None,\n",
            "                           solver='svd', store_covariance=False, tol=0.0001)\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    74.26900584795322\n",
            "BALANCED ACCURACY SCORE:    77.81954887218046\n",
            "f1 SCORE:    81.19658119658119 \n",
            "\n",
            "\n",
            "\n",
            "74.26900584795322\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.46      0.59        70\n",
            "         1.0       0.71      0.94      0.81       101\n",
            "\n",
            "    accuracy                           0.74       171\n",
            "   macro avg       0.78      0.70      0.70       171\n",
            "weighted avg       0.77      0.74      0.72       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[32 38]\n",
            " [ 6 95]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Classifier:\n",
            " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    94.73684210526315\n",
            "BALANCED ACCURACY SCORE:    94.87657864523536\n",
            "f1 SCORE:    95.60975609756098 \n",
            "\n",
            "\n",
            "\n",
            "94.73684210526315\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.91      0.93        70\n",
            "         1.0       0.94      0.97      0.96       101\n",
            "\n",
            "    accuracy                           0.95       171\n",
            "   macro avg       0.95      0.94      0.95       171\n",
            "weighted avg       0.95      0.95      0.95       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[64  6]\n",
            " [ 3 98]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Classifier:\n",
            " MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    80.7017543859649\n",
            "BALANCED ACCURACY SCORE:    80.02816901408451\n",
            "f1 SCORE:    83.5820895522388 \n",
            "\n",
            "\n",
            "\n",
            "80.7017543859649\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.77      0.77        70\n",
            "         1.0       0.84      0.83      0.84       101\n",
            "\n",
            "    accuracy                           0.81       171\n",
            "   macro avg       0.80      0.80      0.80       171\n",
            "weighted avg       0.81      0.81      0.81       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[54 16]\n",
            " [17 84]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Classifier:\n",
            " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
            "                       n_jobs=None, oob_score=False, random_state=80, verbose=0,\n",
            "                       warm_start=False)\n",
            "\n",
            "\n",
            "ACCURACY SCORE:    93.56725146198829\n",
            "BALANCED ACCURACY SCORE:    93.27464788732394\n",
            "f1 SCORE:    94.52736318407959 \n",
            "\n",
            "\n",
            "\n",
            "93.56725146198829\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.93      0.92        70\n",
            "         1.0       0.95      0.94      0.95       101\n",
            "\n",
            "    accuracy                           0.94       171\n",
            "   macro avg       0.93      0.93      0.93       171\n",
            "weighted avg       0.94      0.94      0.94       171\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[65  5]\n",
            " [ 6 95]] \n",
            " ----------------------------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#IMPORTING MODULES FROM PACKAGES\n",
        "\n",
        "# from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n",
        "\n",
        "\n",
        "#cALCULATING ACCURACY BY LOGIC CODING\n",
        "def accuracy(X_Test,Y_Test,classification):\n",
        "  print(\"Classifier:\\n {}\".format(classification)+\"\\n\"*2)\n",
        "  Y_pred=classification.predict(X_Test)\n",
        "  correct=0\n",
        "  total=len(Y_pred)\n",
        "  for i,j in zip(Y_pred,Y_Test):\n",
        "    if(i==j):\n",
        "      correct+=1\n",
        "  acc=(correct/total)*100\n",
        "\n",
        "# FINDING ACCURACIES USING METHODS  \n",
        "  #print(r2_score(Y_pred,Y_Test)\n",
        "  print(\"ACCURACY SCORE:   \",accuracy_score(Y_pred,Y_Test)*100)\n",
        "  print(\"BALANCED ACCURACY SCORE:   \",balanced_accuracy_score(Y_pred,Y_Test)*100)\n",
        "  print(\"f1 SCORE:   \",f1_score(Y_pred,Y_Test)*100,\"\\n\"*2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(\"\\n\"+str(acc)+\"\\n\"+\"-\"*50)\n",
        "  print(\"\\n\"+ \"\\n\"+classification_report(Y_Test,Y_pred)+\"\\n\")\n",
        "  print(\"Confusion Matrix:\\n\",confusion_matrix(Y_Test,Y_pred),\"\\n\",\"-\"*100+\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "for classifier in classification_list:\n",
        "  accuracy(X_Test,Y_Test,classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHgXEtH5r5eX"
      },
      "source": [
        "CONFUSION MATRIX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ogOXhGrfE1"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MgyU7CsMJ1"
      },
      "source": [
        "PRECISION,RECALL,ACCURACY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRUfJwODsH1Q"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5VU9F3nyBaE"
      },
      "source": [
        "IN THIS TASK WE TRAINED 8 DIFFERENT MODELS ON CLASSIFICATION PROBLEM OF THE BREAST CANCER DATASET USING DIFFERENT USEFUL LIBRARIES AND BOTH KNEIGHBORSCLASSIFIER AND SUPPORT VECTOR MACHINE MODELS STOOD OUT FROM ALL THE OTHER 6 MODELS WITH ACCURACY OF 95.32%."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Breast_Cancer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
